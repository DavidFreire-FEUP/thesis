\chapter{Consumer Group Autoscaler} 
\label{chap:consumer_group_autoscaler}

\section{Problem Formulation}

As shown in figure \ref{fig:problem_context}, the data pipeline consists of
extracting data from Kafka topics and inserting it into a data lake to be
further treated in the remaining ETL processes.  The work developed throughout
this thesis, aims to optimize the pipeline from Kafka into BigQuery, by
providing a dynamic solution that makes use of Kafka's parallelism without
disregarding the cost of the number of instances deployed. 

The aim is to achieve a deterministic approach as for the number of consumers
required working in parallel, so as to guarantee that the rate of production
into a topic is not higher than the rate of consumption. In contrast, if this
were not the case, messages would accumulate in a topic leading to the lag
between the last message inserted and the last message read by the consumer
group increase with time.

A Kafka topic is subdivided into several partitions, distributed within the
several brokers of the Kafka cluster. When sending a message into a topic, if a
key is provided, then the message will consistently end up in the same
partition, whereas if none is provided, then the message is inserted in a
round-robin fashion in one of the partitions of the same topic. Messages going
into a topic may also have different sizes ($bytes$), and for these reasons, the
write speed ($bytes/s$) to the several partitions in a topic is not guaranteed
to be the same. 

The following model, also assumes that the maximum consumption rate of a single
consumer is constant, and if there is enough data to be consumed, this is the
speed the consumer functions at when working "full throttle". This is
elaborated in Section \ref{result:bin capacity} based on several tests performed
to determine this value for a consumer. 

Based on the previous information, the model for this pipeline is considered to
fit the constraints for the SBSBPP, where the consumer is the bin that has as
capacity its maximum consumption rate, and the weights are the partitions and
their respective write speeds. The problem then is to find the minimum amount of
consumers where to fit all the partitions so as to make sure that the sum of the
write speeds of the partitions assigned to a single consumer does not exceed its
maximum capacity. 

For a single iteration, the optimal solution finds the arrangement between the
partitions and the consumers that minimizes the amount of instances, but this
solution is not static, as the write speeds of the partitions changes with time.
As such, there is a second factor to take into consideration which is the
partition reassignment. 

When a partition is reassigned, because two consumers from the same group cannot
be consuming from the same partition at a time, when assigning a partition to
another consumer, the one it is currently assigned to has to stop consuming in
order to allow the new consumer to start. Due to this process, there is some
downtime where data is not being consumed from a partition.

For this reason, making use of an optimal algorithm that also minimizes
partition redistribution, is not feasible as it would not run within the
necessary time requirements due to the NP hard nature of the problem.  To
determine the arrangement of partitions and consumers, this work is based on the
studied approximation algorithms which have already been mentioned in the
literature review. As is clear, there is no approximation algorithm which
considers item redistribution. The reason for this may lay on the fact that the
context where this problem lies is not very common, and there is no mention of a
stateful assignment where each item is already assigned a bin prior to executing
the algorithm.

Due to the dynamic nature of the problem the items change in size depending on
the measurement performed at time instant $t$. Consequently, constraint
\ref{opt:c1} is remodeled to take the time instant $t$ at which the algorithm is
to be executed into account.
\begin{alignat}{3}
\label{BPP model}
    &\min       
        &&\sum_{i \in B} y_i 
            && \\
    &\text{subject to} \quad
        && \sum_{j \in L} \hat w_j(t) \cdot x_{ij} \leq y_i \quad      
            && \forall \; i \in B \\
    &   && \sum_{i \in B} x_{ij} = 1, \quad                             
            && \forall \; j \in L \\
    &   && y_i \in \{0, 1\}                                             
            && \forall \; i \in B \\
    &   && x_{ij} \in \{0,1\}                                           
            && \forall \; i \in B, j \in L
\end{alignat}

Time instant $t$ represents an instant at which a measurement was performed of
the items' sizes, leading to a new computation of the bin packing assignment,
and new values for $x_{ij}$ and $y_i$. Since an assignment represents a
consumer reading data from the partition, an item can also be reassigned to
another consumer (bin) adding a new variation to the traditional BPP. 

\begin{figure}[htb!] \centering
    \includegraphics[width=\textwidth]{images/controller/System Design.png}
    \caption{System architecture.} 
    \label{fig:system_architecture}
\end{figure}

As presented in figure \ref{fig:system_architecture}, there are three components
that interact with one another in order to model the problem as a BPP, and to
provide a fully dynamic pipeline capable of autoscaling based on the current
load of data being produced to the partitions of interest. The monitor process
is responsible for measuring the write speed of each partition the group is
interested in consuming data from, which is equivalent to specifying the size of
the items of the BPP.  This information is then delivered to the controller,
which is responsible for managing a consumer group (creating and deleting
consumer instances), and mapping each partition to a consumer. The consumers are
then informed of their tasks and read the data from the partitions that were
assigned to them by the controller.

\begin{comment}
    The Data-Engineering (DE) team at HUUB is responsible for making a pipeline that
    inserts data from several data sources into a data lake so it can then be
    transformed and loaded into a single source of truth data warehouse. 

    HUUB's current architecture makes use of event sourcing to announce events that
    change the system's state within a microservice. Prior to this architecture, it
    was common to fetch the information from several different databases which were
    of interest for this department, periodically and in batches, which lead to
    tight coupling between the work performed by the different teams at the company.

    Based on reporting and real-time data needs, with regards to the extraction
    process, if there is new data that has to be consumed from a service that isn't
    currently being consumed, Kafka and event sourcing allow this addition to be as
    simple as subscribing the DE consumer to the topic of interest.
\end{comment}

\section{Monitor} \label{component:Monitor}

\IncMargin{1em} 
\begin{algorithm}[h]
    \SetKwData{Left}{left}
    \SetKwData{This}{this}
    \SetKwData{Up}{up}
    \SetKwFunction{Union}{Union}
    \SetKwFunction{FindCompress}{FindCompress}
    \SetKwInOut{Input}{input} 
    \Input{ 
        admin - Kafka admin client to communicate with cluster, \\ 
        producer - Kafka producer client, \\ 
        topics - list of topic identifiers from which the monitor is to
        determine the speed of their partitions 
    } 
    \BlankLine

    measurementQueue $\gets$ Queue<Measurement>()\; 
    \While{true}{ 
        measurement $\gets$ new Measurement()\; 
        measurement.partitionSizes $\gets$ admin.getLogDirs(topics)\; 
        measurement.timestamp $\gets$ currentTime()\;
        measurementQueue.add(measurement)\; 
        \If{(measurementQueue.first.timestamp - measurement.last.timestamp) > 30s}{ 
            sizeDiff $\gets$ measurement.last.partitionSizes - measurement.first.partitionSizes\;
            timeDiff $\gets$ measurement.last.timestamp - measurement.first.timestamp\;
            measurementSpeed $\gets$ sizeDiff / timeDiff\;
            producer.producer("monitor.writeSpeed", measurementSpeed)
            \While{(currentTime() - measurementQueue.first.timestamp) > 30s}{
                measurementQueue.pop()\; 
            } 
        } 
    } 
    \caption{Monitor process pseudo-code.}
\label{algo:monitor} \end{algorithm}\DecMargin{1em}

To solve the BPP, initially the controller requires as input the write speed of
each partition the consumer group is interested in consuming data from. The
monitor process is responsible for providing this information.

If enabled, Kafka exposes metrics to external Java processes through Java
Management Extensions (JMX). Prometheus, an open source monitor process, can
then be used as a wrapper to these metrics as it creates a unified model to
query the data, and it also registers the data as a timeseries, allowing for a
historic view of any parameter, as well as creating more elaborate metrics over
the exposed cluster metrics. At the time of writing this thesis and to the best
of my knowledge, there is no available metric that provides a partition's write
speed.  For this reason, this section aims to explain the process that is
responsible for monitoring the write speed of the partitions of interest.

Kafka provides an Admin client, which can be used to administer the cluster, and
also query information about it. This client/class exposes a method
\lstinline[language=Python]{describeLogDirs()} which queries the cluster for the
amount of bytes each TopicPartition has. A TopicPartition is a string-integer
pair, which identifies any partition (integer) within a topic (string). 

Since the consumer only consumes from the partition leader, if the
\lstinline[language=Python]{replication-factor > 1}, then several partitions are
excluded from the result of the previous method call, since this process is only
interested in the partitions that belong to one of the topics of interest, and
which are leaders.

Each time the partition size is queried by the admin client, a timestamp is
appended to the measurement, and it is inserted to the back of the queue. Any
query that is older than $30$ seconds, which is guaranteed to be in the front of the
queue, is removed. To obtain the write speed of a single partition, the last
element of the queue and the first (representing the latest and the earliest
measurement of the partition size within the last $30$ seconds) are used to compute the
ratio between the difference in bytes and the difference in time ($bytes/s$).
This is also the average write speed over the last 30 seconds.

Every topic has the parameters \lstinline[language=Python]{retention.ms} and
\lstinline[language=Python]{retention.bytes}, which determine how long a record
remains in a partition before being deleted, or how many bytes a partition
retains before removing old records. When a record is deleted, the partition
size reduces as it no longer reserves space for the removed record. For this
process to have an accurate write speed, it is important to set both of these
parameter to \lstinline[language=Python]{-1}, which means that the record is
never deleted from the partition. Ideally, the admin client would be able query
for the historic size of a partition, but since this information could not be
retrieved, this approach was what was implemented.

After computing the write speed for all the partitions of interest, the message
has to be communicated to the controller/orchestrator that runs the algorithm to
assign the partitions to the consumers. To benefit from an asynchronous
approach, this monitor process communicates with the controller/orchestrator
process via a Kafka topic named \lstinline{monitor.writeSpeed}, as shown in
figure \ref{fig:system_architecture}. The data to be inserted is the write speed
of the partitions of interest, which is then consumed by the
controller/orchestrator to be used as input for an algorithm's execution.

Two testing scenarios were developed to illustrate the measured partition write
speeds by this method when a controlled producer is sending records at a
predefined rate. The payload inserted into the partition is always 123 bytes.

The first scenario has the producer send the message at three different rates for
approximately 35 seconds each, to simulate a step input. As can be seen in
figure \ref{fig:monitor_step}, the monitor increases the measured write speed
rate slower than the actual speed as measured by the producer. This happens
because the monitor takes into consideration the first and last measurement made
in the last 30 seconds, whereas the producer simply measures the produce rate
since the last time it inserted a record into the partition. It takes the
monitor 30 seconds to converge to the actual production speed where it then
settles until the produce rate increases again.

\begin{figure}[htb!] 
    \centering
    \includegraphics[width=0.7\textwidth]{images/monitor/step.png}
    \caption{Monitor step response to three different controlled write speeds.}
    \label{fig:monitor_step} 
\end{figure}

Since a message broker receives data at variable rates from multiple producers
at a time, the second scenario aims to test a noisy test case, where producers
send data at different rates to a partition. This was done by having a producer
wait randomly between $[0.01, 2]$ seconds before sending the payload, to
increase the variability in the producer's measured speed. Provided the monitor
takes into consideration the last 30 seconds from its latest measurement, it is
not affected by the noisy write speed. Within these testing conditions, due to
the wait time being modeled as a uniform random variable, the monitor process
should stabilize at approximately the speed computed using the number of bytes
produced and the expected wait time, which in this case are 123 bytes and
approximately 1 second respectively. This is in fact the case as can be seen in
Figure \ref{fig:monitor_random}, since the write speed stabilizes around $123
bytes/s$. Figure \ref{fig:monitor_random_boxplot} presents a statistical
description of the producer's measured write speed, that better illustrates the
noise reduction in the monitor's measurement due to the computed average.
\begin{figure}[!htb] 
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/monitor/random_without_boxplot.png}
        \caption{
            Producer's speed measured between each production instant.
        }
        \label{fig:monitor_random} 
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/monitor/random_with_boxplot.png}
        \caption{
            Producer's speed statisctically summarized using a boxplot.
        }
        \label{fig:monitor_random_boxplot} 
    \end{subfigure}
    \caption{
        Measured write speed by the monitor and the producer, when the
        producer randomly waits between $[0.01, 2]s$ between 2 consecutive
        inserts.
    }
\end{figure}


\section{Consumer} \label{component:consumer}

The Consumer goes through four important phases within its process, to
approximate its consumption rate to a constant value when being challenged to
work at its peak performance. These phases repeat cyclically until the consumer
is terminated by an external termination signal. 

\begin{figure}[htb!] 
    \centering
    \includegraphics[width=\textwidth]{images/consumer/consumer_cycle.png}
    \caption{Consumer Insert Cycle.}
    \label{fig:consumer_cycle} 
\end{figure}

The following Sections describe each phase in the consumer insert cycle, as
illustrated in Figure \ref{fig:consumer_cycle}.

\subsection{Phase 1: Gathering Records}

The first phase is where data is gathered before being sent to the data
warehouse. The consumer is configured with two important parameters,
\lstinline[language=Python]{BATCH_BYTES} and
\lstinline[language=Python]{WAIT_TIME_SECS}, which indicate respectively, the
amount of bytes the consumer waits to gather in a single iteration, and the
amount of time it is allowed to wait to gather the information.

\subsection{Phase 2: Processing} \label{consumer:phase2}

\IncMargin{1em} 
\begin{algorithm}[h]
    \SetKwData{Left}{left}
    \SetKwData{This}{this}
    \SetKwData{Up}{up}
    \SetKwFunction{Union}{Union}
    \SetKwFunction{FindCompress}{FindCompress}
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output} 
    \Input{\\ 
        messages - List of Kafka messages, \\ 
        mapTopicsTable - Map that indicates which table a message from a topic
            is inserted into 
    } 
    \Output{List<BatchList>} 
    \BlankLine

    mapTableBatchlist $\leftarrow$ new Map[String, BatchList]()\; 
    \For{msg in messages}{ 
        table $\leftarrow$ mapTopicTable.get(msg.topic())\; 
        batchList $\leftarrow$ mapTableBatchlist.get(table)\; 
        \If{(batchList == None)} {
            mapTableBatchlist[table] $\leftarrow$ new BatchList()\; 
            batchList $\leftarrow$ mapTableBatchlist.get(table)\; 
        } 
        batchList.add(msg)\; 
    }
    \KwRet{mapTableBatchlist.values()} 
\caption{Consumer Phase 2 algorithm}
\label{algo:phase_2} 
\end{algorithm} 
\DecMargin{1em}

The second phase is where the data gathered in the previous phase is prepared to
be sent into the datalake, which in this case is bigquery. Each record fetched
from a Kafka topic, represents a new row in a bigquery table. 

To insert data into bigquery, Google's Python Bigquery Client is used. Each post
request made with this client, has a batch of rows sent to a single table, and
it is also limited to no more than $10Mbytes$ per request.

Since the gathered records originate from multiple topics, each row has to be
batched with data of its kind, which are rows that are intended to be sent to
the same bigquery table.  A single instance of a Batch, a data structure created
to agglomerate rows intended for the same bigquery table, holds all the rows
which will be sent in a single post request through Google's python bigquery
client API. Due to the imposed limit of a post request, a Batch has a payload
limit of $5 Mbytes$.  A BatchList, is another data structure created to group
instances of type Batch that refer to the same table.

To process the data, a map stores the link between a table's id and the
BatchList instance assigned to it. When analyzing a message, its topic metadata
indicates which table it is directed to, which in turn points to the BatchList
it must be added to.  When adding a message to a BatchList instance, this class
controls to which Batch it is assigned, based on the size of the row, and the
size of the last created Batch within this data structure.

\subsection{Phase 3: Sending Records to the Data Lake}

This is the final stage of the consumer's insert cycle. There is a list of
BatchList instances, each having to be sent to a single bigquery table. To
optimize the insert cycle, this phase is done asynchronously with respect to all
the batches within the list of BatchLists contained in the map specified in
algorithm \ref{consumer:phase2}. In other words, each batch corresponds to an
asynchronous request to insert rows into a table. After successful insert of the
rows into the bigquery table, the messages are then committed to Kafka. 

\subsection{Phase 4: Update Consumer Metadata}

\IncMargin{1em} 
\begin{algorithm}[h]
    \SetKwData{Left}{left}
    \SetKwData{This}{this}
    \SetKwData{Up}{up}
    \SetKwFunction{Union}{Union}
    \SetKwFunction{FindCompress}{FindCompress}
    %\SetKwInOut{Output}{output}
    \SetKwInOut{Input}{input} 
    \Input{
        consumer - consumer instance used to fetch information from the Kafka topics.
    }
    %\Output{} \BlankLine

    Set<Partition> current $\gets$ consumer.getCurrentState()\; 
    Set<Partition> future $\gets$ current.copy()\;

    Queue< Set<Partition> > changeStateQueue $\gets$ consumer.consumeMetadata()\;
    \While{changeState $\gets$ changeStateQueue.pop()}{ 
        \eIf{changeState.type == "StopConsumingCommand"}{ 
            future $\gets$ future - changeState.partitions\; 
        }{
            future $\gets$ future $\cup$ changeState.partitions\; 
        } 
    } 
    toAssign $\gets$ future - current\; \label{algo:phase_4_toAssign} 
    toStop $\gets$ current - future\; 
    consumer.incrementalAssign(toAssign)\;
    consumer.incrementalUnassign(toStop)\; \label{algo:phase_4_incremental_assign}

\caption{Consumer Phase 4 algorithm} 
\label{algo:phase_4}
\end{algorithm}
\DecMargin{1em}

The consumer has to be informed by the Controller, as to which partitions it
gets data from. For this purpose, to allow both the controller and the consumers
to work asynchronously, a message queue is the ideal structure for this purpose.

Following event sourcing patterns, the current state of a single consumer should
be attained by consuming every message that was directed to it, which enforced a
change in state. With a slight modification, Kafka is used for this
communication between the controller and the consumers by creating a single
controller topic named \lstinline[language=Python]{consumer.metadata}.

Maximum efficiency in data conveyed between each process, occurs when a single
process only reads messages which are relevant for its functioning, without
having to ignore messages or data that it receives. As such, each consumer has
to be assigned a separate queue in the
\lstinline[language=Python]{consumer.metadata} topic, which in Kafka represents
a distinct partition per consumer.

As we further describe in Section \ref{component:controller}, the consumer
knows which partition to consume from through its deployment's name. When the
controller desires to communicate with this consumer, it simply has to send a
record to its partition. 

Each record published into this topic has to have the same AVRO schema as
specified by the schema in Appendix \ref{appendix:avro_schema}. A command can be either
a: 
\begin{itemize} 
    \item StartConsumingCommand - The consumer is to start
        consuming from each of the partitions within the record.  
    \item StopConsumingCommand - The consumer stops consuming from the
        partitions specified in the record.  
\end{itemize}

The fourth phase starts with the consumer determining whether there are any
messages in its metadata queue (the partition it was assigned from the
\lstinline{consumer.metadata} topic). If there are none, the consumer's state
isn't changed, and the phase is finalized. Otherwise, if there are any messages
in the queue, the consumer goes through the process of consuming all the
messages in the metadata partition, and adds them to a Queue instance
\lstinline{changeStateQueue}.

The next step is to process the \lstinline{changeStateQueue}. Initially, a set
is created where each element represents a partition from a topic the consumer
is currently consuming from. This set is stored in the variable
\lstinline{current}. A copy of this set is made and assigned to a variable
\lstinline{future}. While the queue is not empty, the front-most element is
removed and assigned to a temporary variable \lstinline{changeState}. Depending
on the command, if the record requests the consumer to start consuming from its
set of partitions then a union operation is performed between the
\lstinline{future} and the \lstinline{changeState}. In turn, if the record is of
type "StopConsumingCommand", the difference between \lstinline{future} and
\lstinline{changeState} is computed.

Having processed the whole \lstinline{changeStateQueue}, future holds the new
state the consumer has to change into. Lines \ref{algo:phase_4_toAssign} to
\ref{algo:phase_4_incremental_assign} change the consumer's assignment into
future's state.

\subsubsection{Persisting Metadata}

The consumer's final stage has it persisting its metadata for the case it
unexpectedly fails and has to pick up the work it was last performing. This
avoids having the consumers reprocess the whole metadata queue to reach its last
state. The data to be persisted is the set of partitions it is currently
consuming from. A successful change in consumer state would only occur after the
consumer successfully persists the data to its persistent volume.

When dealing with Kubernetes pods, by default the pod's storage is ephemeral,
which means that the group of containers starts with a clean slate, and when
terminated the data written to disk is cleaned, making it inacessible for future
reads outside of a single pods lifetime.

Kubernetes provides volumes which can be of type ephemeral or persistent (its
lifetime is independent of the pod's). A persistent volume (PV) can be created
static or dynamically, and is a resource within the cluster. A persistent volume
claim (PVC), is a method of abstraction which allows a user to request for
storage. This request, then tries to match the claim to one of the available
resources (PVs), and if there are none available, then a new persistent volume can be
created dynamically if the Storage Class is defined. The mapping between PV and
PVC is one-to-one.

This consumer uses both types of volumes, since the downwardAPI is of type
ephemeral and it provides the consumer with its context, giving it access to its
deployment's name (data the consumer requires for it to know which partition to
consume from in the \lstinline{consumer.metadata} topic).  As for the persistent
volume, the consumer will use this type of volume to persist the data for its
current consumption state. If the consumer fails unexpectedly, then on startup,
it just has to verify its state on the volume, and in case it was performing any
tasks, it picks up where it left off.

When stopping a consumer, to safely terminate its tasks, the controller sends a
StopConsumingCommand for all the partitions the consumer is currently assigned
to. After the consumer acknowledges it acted to the command (it sends a
StopConsumingEvent back to the controller), the controller then terminates the
pod. This communication between the controller and the consumer is better
described in Section \ref{sub:controller_communication_cosumer}. 

The fact termination only occurs after the consumer updates its metadata,
implies the persistent volume is also updated to an empty set, which allows a
new consumer of the same deployment to start off with a clean slate as should be
the case, since the consumer was gracefully terminated.


\subsection{Consumer Maximum Capacity}
\label{c3subsub:consumer_maximum_capacity}

The way the problem is formulated assumes the consumer is capable, when
required, to achieve a maximum data consumption rate (still to be defined),
analogous to the capacity of a bin in a BPP.

With the goal of attaining a value for this maximum bin capacity, the consumer
was tested in 3 different scenarios, each requiring the consumer to be working
at peak performance.  Peak performance is defined as the case when the sum of
the bytes still to be consumed from all the partitions the consumer is assigned
to is bigger than \lstinline{BATCH_BYTES}. The three testing scenarios aim to
test the consumer's throughput while varying the number of tables it has to
insert data into, the average amount of bytes available in each of the assigned
partitions, and the number of partitions assigned to it.

The consequence of having more tables where data has to be inserted directly
affects the third phase by increasing the amount of asynchronous requests that
have to be made. Reducing the average amount of bytes available in the
partitions assigned, but still being able to make the consumer work at full
capacity, aims to test the first phase of the algorithm, where the data has to
be consumed from the partitions assigned from Kafka.  This is the case since
this high-level consumer is based on the Kafka client provided by the
\lstinline{confluent_kafka} package.  When the client begins, it starts a
low-level consumer implemented in C that runs in the background. As the
low-level consumer runs, it buffers messages into a queue until the high level
python consumer requests for what it has consumed with either \lstinline{poll()}
or the \lstinline{consume()} methods. The difference between these two methods
is that the first returns a single message whereas the second returns a batch of
messages defined by \lstinline{num_messages}, from the low level client's
buffer. 

To improve throughput, when a consumer requests for data from the broker, the
broker attempts to batch data together before sending it back to the consumer.
Configuration parameters \lstinline{fetch.max.bytes} and
\lstinline{fetch.max.wait.ms} define how a single request is handled by the
broker, wherein the first determines the maximum amount of bytes returned by the
broker, and the second, the amount of time the broker can wait before returning
the data if fetch.max.bytes is not satisfied.

Reducing the average amount of bytes in each of the partitions assigned, leads
to the consumer having to perform more requests to fetch the same amount of data
defined by \lstinline[language=Python]{BATCH_BYTES}. 

The number of partitions assigned to the consumer is expected to influence the
time it takes for the consumer to gather
\lstinline[language=Python]{BATCH_BYTES}, by increasing the amount of requests
required to fetch the data, as assigning partitions increases the probability of
the consumer having to communicate with more brokers. 

Another important definition is that the consumer is said to have reached its
steady state, when it is capable of fetching
\lstinline[language=Python]{BATCH_BYTES} prior to
\lstinline[language=Python]{WAIT_TIME_SECS} being triggered in its first phase.
This reflects that the low-level consumer is capable of gathering the necessary
amount of bytes into its buffer, while the high-level consumer is running all
the remaining phases except the first of the insert cycle.

For the following test cases, \lstinline[language=Python]{BATCH_BYTES = 5000000}
and \lstinline[language=Python]{WAIT_TIME_SECS = 1}.  These values inherently
reflect the time it takes for a consumer to go through each of its phases, and
the rate at which it can consume data.

\begin{table}[H] 
\centering 
\caption{
    Testing conditions to obtain consumer maximum throughput measure.
} 
    \begin{tabular}{ |c|r|r|r|r| } 
        \hline
        \textbf{Test ID} & \textbf{Total Bytes} & \textbf{Average Bytes} &
            \textbf{Number of Partitions} & \textbf{Number of Tables} \\ 
        \hline 
        Test 1 & $648\ Kbytes$ & $20\ Kbytes$ & $32$ & $1$ \\ 
        Test 2 & $100\ Kbytes$ & $0.86\ Kbytes$ & $116$ & $5$ \\ 
        Test 3 & $678\ Kbytes$ & $4\ Kbytes$ & $144$ & $5$ \\ 
        \hline
    \end{tabular} 
\end{table}

Test 1 has the consumer fetching records which are all directed to the same
table, and every partition it visits has enough bytes to satisfy the
\lstinline{max.fetch.bytes} condition, optimizing the throughput between the
low-level consumer and the brokers, as the data is batched together. Since there
is only one table to send the data to, the third phase is also optimized as
there will only be a single BatchList instance.

As for Test 2, the increased number of partitions and the reduced average amount
of bytes in each partition has the consumer polling more brokers to gather
\lstinline{BATCH_BYTES}, increasing the time the consumer takes in the first
phase. Although the time taken in this phase increased The average time it takes
the consumer to fetch \lstinline{BATCH_BYTES} from the kafka cluster, indicates
that the consumer still manages to reach its steady state.

Lastly, Test 3 combines both of the previous scenarios, where there is more data
per partition to be sent back to the consumer, although some iterations require
the consumer to send data to five different tables since the data originates from
partitions that belong to different topics.

The metrics that were deemed important for the analysis of the consumer's
behaviour, were: Time of Phase 1 ($\Delta t_{P1}$); Time of Phase 2 ($\Delta
t_{P2}$); Time of Phase 3 ($\Delta t_{P3}$); Total cycle time ($\Delta t$);
Measured cycle throughput.

Each of these parameters is statistically summarized in table
\ref{tab:consumer_results}:
\begin{table}[H] 
\centering 
\caption{Statistical summary of the metrics.}
\label{tab:consumer_results}
    \begin{tabular}{ |c|l|r|r|r|r|r| } 
        \hline 
        \textbf{Test ID} & \textbf{Summary Measure} & \textbf{$\Delta t_{P1}$} &
            \textbf{$\Delta t_{P2}$} & \textbf{$\Delta t_{P3}$} & \textbf{$\Delta t$} & \textbf{Throughput} \\ 
            \hline
            \multirow{2}{*}{Test 1} 
            & Average & 0.394  & 0.000775 & 1.69 & 2.08 & 2418855 \\ 
            & Standard Deviation & 0.0338 & 0.00620  & 0.0941 & 0.101 & 97853 \\ 
            \hline 
            \multirow{2}{*}{Test 2} 
            & Average & 0.462 & 0.00684 & 1.72 & 2.18 & 2307501 \\ 
            & Standard Deviation & 0.125 & 0.001600  & 0.0946 & 0.169 & 171231 \\ 
            \hline \multirow{2}{*}{Test 3} 
            & Average & 0.397  & 0.00896 & 1.68 & 2.08 & 2418220 \\ 
            &  Standard Deviation & 0.0466 & 0.00619 & 0.105 & 0.121 & 132017 \\ 
    \hline 
    \end{tabular} 
\end{table}

The following graph demonstrates how the consumer is capable of maintaining a
stable speed above a threshold of $2 Mbytes/s$, when it finds itself in its
steady state (capable of consuming $5 Mbytes$ before
\lstinline[language=Python]{WAIT_TIME_SECS} is triggered), sharing a mode
between the three different testing scenarios around $2.3 Mbytes/s$.

\begin{figure}[H] \centering
\includegraphics[width=0.7\textwidth]{images/consumer/density.png}
\caption{
    Density Plot for the consumer's measured throughput in the three testing
    conditions.
} 
\label{fig:consumer_capacity} 
\end{figure}

\subsubsection{Bin Capacity} \label{result:bin capacity}

Two measures are defined in order to run the heuristics described in section
\ref{component:controller}. The \lstinline{ALGORITHM_CAPACITY},
is the constant bin size that will be used when running all the heuristic
algorithms when solving the dynamic BPP, whereas the
\lstinline{CONSUMER_CAPACITY} is the consumer's maximum
capacity, which if exceeded, must trigger a new configuration as for which
partition should be assigned to which consumers.

The reason for having defined these two configuration parameters are due to the
problem's dynamic nature. Since the measured write speed for each partition
varies between each measurement, after executing the BPP algorithm for a single
measurement, it is common to have bin's filled close to their capacity, which
would lead to excessive rebalancing computations if the algorithm and consumer
capacity were defined using the same value. Defining the Consumer's capacity to
a value higher than the algorithm's perceived capacity, reduces the number of
rebalances triggered, at the cost of a reduced bin capacity. 

From graph \ref{fig:consumer_capacity}, the Consumer's capacity is set to $2
Mbytes/s$, whereas the Algorithm's capacity is defined as $1.5 Mbytes/s$.  These are
the values used for the remaining part of the work.  It is important to note
that these values are only valid when the consumers are deployed in the
environment where they were tested. Having executed the test in multiple
environments, it can be said that the consumer's maximum capacity does not
change between consumer instances as long as the environment is similar for all
consumers.

\section{Controller/Orchestrator} \label{component:controller}

The controller is the component of the system which is responsible for
orchestrating and managing the consumer group that is intended to consume the
data from the partitions of interest.  The problem is modeled as a dynamic bin
packing problem, where the size of each item is equivalent to the write speed of
each partition, and the size of the container represents the maximum achievable
speed of a consumer which has been provided by the data presented in section
\ref{result:bin capacity}.

At any given time, no consumer within the consumer group can have its capacity
exceeded by the cumulative write speed of the partitions assigned to it, and if
that is the case, then a rebalance has to be triggered. The same applies in case
a partition has not yet been assigned a consumer.

After the controller determines the state in which it wants its consumer group,
it then creates the consumers that don't yet exist, communicates the change in
assignment to each consumer in the group, followed by deleting the consumers
that are not required in the new computed group's state.

\subsection{Rscore}
\label{sub:rscore}

Within this problem's context, rebalancing inevitably implies having the
consumer group stop consuming from a partition while the controller is
reassigning the partition from one consumer to another (as there cannot be a
concurrent read from the same partition by members of the same group).

A new measure is proposed to compute the total rebalance cost (Rscore) of a new
group's configuration, which aims to reflect the impact of rebalancing a set of
partitions in an iteration due to temporarily stopping data consumption from
all rebalanced partitions during the rebalance phase (described
in section \ref{sub:controller_communication_cosumer}). As such, the Rscore
computes the rate at which information is accumulating, in consumer iterations
per second.

\begin{table}[H] 
\centering 
\caption{Data to compute the Rscore for an iteration.} 
\label{tab:rscore_data}
    \begin{tabular}{ |c|l| } 
        \hline 
        \textbf{Symbol} & \textbf{Description} \\ 
        \hline 
        $P_i$ & set of partitions that were rebalanced in iteration $i$ \\ 
        $s(p)$ & The write speed of partition $p$ \\ 
        $C$ &  Constant that represents the maximum consumer capacity from
            section \ref{result:bin capacity}\\ 
        \hline 
    \end{tabular} 
\end{table}

Provided the data presented in table \ref{tab:rscore_data}, the following
equation presents the rebalance cost (Rscore) for a single iteration $i$ ($R_i$).

\begin{equation} 
    R_i = \frac{1}{C}\sum_{p \in P_i} s(p) 
\end{equation}


\subsection{System Design}

As has been described, there are three different components in the system that
work together to get the data from Kafka into bigquery. To do so, each component
has to be able to communicate with one another to inform any change in state.

As shown in figure \ref{fig:system_architecture}, page
\pageref{fig:system_architecture}, there are two main topics that will be
responsible for providing an asynchronous communication between the 3 different
entities of the system. The \lstinline{monitor.writeSpeed} topic, is where the
monitor process sends the speed measurements for the controller to consult,
whereas the \lstinline{consumer.metadata} topic is where the controller sends
messages to each consumer to inform the change in their state. Partition 0 of
the \lstinline{consumer.metadata} topic is reserved for communication which is
intended to reach the controller.

When using a Kafka topic to communicate between the consumers and the controller
there are certain requirements that need to be complied with. The first, is that
when the controller desires to communicate with a consumer from the consumer
group, it has to be guaranteed that the message reaches the intended consumer. 

Secondly, as will be common with this system, the controller will create and
delete a single consumer multiple times in its lifecycle. The message offset a
consumer starts on after restarting, has to be precisely the one where it left
off before being shut down by the controller. This can be done leveraging
kafka's \lstinline{group-id} property defined in each consumer client, so the
system just has to guarantee that the consumer gets the same id as before, and
that no other client with the same id consumed messages from this consumer's
queue.

Thirdly, each consumer only reads messages which are intended to it. This would
represent maximum efficiency in the information transmitted between both
controller and consumer, since no process is reading messages or data that has
to be ignored. To better understand this design requirement, the following
scenario is described: It might happen that a certain number of consumers
satisfies the controller's conditions, without any need to scale up or down the
group. This would imply that the control messages sent by the controller are
only read by the current active consumers. When a new consumer is started by the
controller, if the messages are shared, then there is a big queue of messages
that have not yet been read by the new consumer since it was last up. For the
new consumer to be able to read new control messages sent by the controller, it
would first have to read all messages that were not intended to it prior to it
starting up.

Lastly, to guarantee temporal consistency in the control messages sent to a
single consumer, it is clear that a control message can only be sent to a single
partition, as kafka only guarantees message read order when the messages belong
to the same partition. Kafka already does this by allowing a message to have a
key attribute which is then hashed to determine the partition in which the
message is to be inserted. The issue with this approach is if the number of
partitions in the \lstinline{consumer.metadata} topic increases, the key might not
send the messages to the same partition as before. As such, each consumer is
given an incremental id ($1, 2, ...$), which represents the partition where
change in state information has to be sent for the consumer to read (both
controller and consumer are aware of this id).

\subsection{State Machine}

The controller can be defined by a state machine, intended to continuously
manage a group of consumers and their assignments. The following sections
will further describe each of the states, which are illustrated in the state
machine in Figure \ref{fig:state_machine}.

\begin{figure}[H] 
\centering
\includegraphics[width=\textwidth]{images/controller/state_machine.png}
\caption{Controller State Machine.} 
\label{fig:state_machine} 
\end{figure}

\subsection{State Sentinel}

This state is where the controller uses the information provided by the monitor
component described in section \ref{component:Monitor}, to determine whether it
has to recompute the consumer group's assignment. The first step the controller
goes through in this state is to read the last speed measurement the monitor
component added to the \lstinline{monitor.writeSpeed} topic.

The controller then updates each of the partition's speeds, which in turn
updates the cumulative speed of each consumer. As can be seen in figure
\ref{fig:state_machine}, there are three transitions that can lead to the
controller re-computing the current consumer group's assignment:
\begin{enumerate} 
    \item \textbf{Consumer Capacity Exceeded} - This transition is triggered if
        the cumulative speed of all the partitions assigned to any consumer,
        exceeds \lstinline{CONSUMER_CAPACITY} obtained in section
        \ref{result:bin capacity}.  
    \item \textbf{Unassigned Partition} - If there is any partition within the
        last speed measurement that is not currently assigned to a consumer,
        then this transition is triggered.  
    \item \textbf{Sentinel Timeout} - One of the controller's configurations, is
        a parameter \lstinline{MAX_S1_TIME} which indicates the
        maximum amount of time the controller can spend in the sentinel state
        without triggering a rebalance. This trigger is to have a condition that
        runs the algorithm to verify if downscaling is viable, as the other
        triggers are directed to upscaling conditions.
\end{enumerate}

\subsection{State Reassign Algorithm}
\label{sub:reassign}

This state receives as input the current consumer group's assignment and the
remaining unassigned partitions, and produces as output a new consumer group
assignment, which is to be defined as the group's future state.

This state uses only approximation algorithms to determine the group's future
assignment. The algorithms implemented are the already existing Next Fit, First
Fit, Worst Fit, Best Fit, and each of the previous algorithms' decreasing
versions, and modified versions of the Best and Worst Fit algorithms, which are
to be further described in Section \ref{subsub:modified_any_fit}. 

In the implementation of the existing approximation algorithms (AA), another step was
included in the bin creation process which does not affect the outcome in terms
of number of consumers of the AA. If the consumer that is currently assigned to
the partition has not yet been created in the future assignment, this is the bin
that is created, otherwise, the lowest index bin that does not yet exist is the
one created.

\begin{figure}[H] 
\centering
\includegraphics[width=0.6\textwidth]{images/controller/ApproximationAlgorithm_NewBin.png}
\caption{
    New bin creation procedure when executing an existing approximation algorithm.
}
\label{fig:approximation_bin_creation} 
\end{figure}

Figure \ref{fig:approximation_bin_creation} illustrates this process, wherein
the first row of consumer's (grey containers) represents the current consumer
group's state, and the second the new consumer group assignment that is being
computed by the controller. Partitions are represented in blue and black, blue
being the partition currently being analyzed by the controller. In this example,
the blue partition currently finds itself assigned to consumer 2. When analysing
the partition, the controller verifies if the partition fits in any of the
existing consumers. Since it does not fit, and another consumer has to be
created to assign this partition, the controller verifies if the consumer that
is currently assigned already exists in the new group's state. Since this is not
the case, the controller proceeds to creating the same consumer and assigning
the current partition to the new bin.

In view of the fact that a group of consumers (bins) already exists at the
moment the approximation algorithm runs to provide a solution to the BPP, this
approach is preferred to simply creating the lowest index bin available as it
reduces the amount of partitions rebalanced. This is not presented as a
modification to the existing algorithms, it simply adapts these to the added
rebalance concern.

\subsection{Modified Any Fit Algorithms}
\label{subsub:modified_any_fit}

The motivation to modifying the existing Any Fit algorithms, is that the
existing algorithms only focus on reducing the amount of bins used to pack
a set of items, disregarding the cost associated with reassigning items.

Since the controller has access to the speed measurements of all partitions and
it does not require to read and assign each partition in any particular order,
this bin packing problem can be categorized as offline.

Given the current consumer group's state (the partitions assigned to each
consumer), and a set of unassigned partitions, the modified algorithms differ
from the previous decreasing versions of the Any fit algorithms described in
Section \ref{section:AA}, wherein this type of algorithm does not sort the set
of items, but in turn the consumers of a consumer group based on their
assignment. 

There will be 2 main approaches to sorting the consumers: 
\begin{itemize} 
    \item Sorting each consumer based on the cumulative speed of all partitions
        assigned to it (cumulative sort); 
    \item Sorting each consumer based on the partition assigned to it that has
        the biggest measured write speed (max partition sort).  
\end{itemize}


\IncMargin{1em} 
\begin{algorithm}[htb!]
    \SetKwData{Left}{left}
    \SetKwData{This}{this}
    \SetKwData{Up}{up}
    \SetKwFunction{Union}{Union}
    \SetKwFunction{FindCompress}{FindCompress}
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output} 
    \Input{current consumer group C and set of unassigned partitions U} 
    \Output{consumer group N which is the next state for the consumer group} 
    \BlankLine 
    N $\leftarrow$ new ConsumerList(assign\_strategy=("BF" | "WF"))\; 
    sorted\_group $\leftarrow$ sort(C, sort\_strategy=("cumulative" | "max partition"))\; 
    \For{consumer $\in$ sorted\_group}{ 
        Set<Partition> partitions $\gets$ consumer.assignedPartitions()\; 
        List<Partition> sorted\_partitions $\leftarrow$ sort(partitions, reverse=True)\; 
        \For{i $\leftarrow$ length(sorted\_partitions)-1 \KwTo 0}{ 
            partition $\leftarrow$ sorted\_partitions[i]\; 
            result $\leftarrow$ assignExisting(N, partition)\;
            \If{result $==$ False}{ 
                break\; 
            } 
            remove(sorted\_partitions, partition)\; 
        }
        \If{sorted\_partitions.length() == 0}{
            continue\; 
        } 
        createConsumer(N, consumer)\; 
        \For{partition $\in$ sorted\_partitions}{ 
            result $\leftarrow$ assignCurrent(N, partition, consumer)\; 
            \If{result $==$ False}{ 
                break\; 
            }
            remove(sorted\_partitions, partition)\; 
        } 
        extend(U, sorted\_partitions)\; 
    }
    sorted\_unassigned $\leftarrow$ sort(U, reverse=True)\; 
    \For{partition $\in$ sorted\_unassigned}{ 
        assign(N, partition)\; 
    } 
    \KwRet{N} 
\caption{Modified Any Fit Pseudo Code}
\label{algo:MBPP} 
\end{algorithm}
\DecMargin{1em}

After sorting the current consumer group using one of the above strategies, for
each consumer in the sorted consumer group, the partitions assigned to the
consumer are sorted based on their write speed. From smallest to biggest, each
partition is inserted into one of the bins that have already been created in the
future assignment, based on one of the any fit strategies, which can either be
the Best or Worst Fit strategy. If the insert is successful, then the partition
is removed from the sorted list of partitions, otherwise, if there is no
existing bin that can hold the partition, then the current consumer assigned to
it is created. 

The remaining partitions in the sorted list are now inserted into the newly
created bin, from biggest to smallest, and removed from the sorted list if
successful. If a partition does not fit into the newly created consumer, then
the remaining partitions in the list of sorted partitions are added to the set
of unassigned partitions.

After performing the same procedure over all consumers, there is now a set of
partitions which have not been assigned to any of the consumers in the future
assignment. The final stage involves first sorting the unassigned partitions in
decreasing order (based on their measured write speed), and each partition is
assigned a consumer from the new consumer group using their respective any fit
strategy.

\begin{table}[H] 
\centering 
\caption{Modified implementations of the any fit algorithms.} 
\begin{tabular}{ |c|c|c| } 
    \hline 
    \textbf{Algorithm} & \textbf{Assign Strategy} & \textbf{Consumer Sorting Strategy} \\ 
    \hline
    Modified Worst Fit & Worst Fit & cumulative write speed \\ 
    Modified Best Fit & Best Fit & cumulative write speed \\ 
    Modified Worst Fit Partition & Worst Fit & max partition write speed \\ 
    Modified Best Fit Partition &  Best Fit & max partition write speed \\
    \hline
\end{tabular} 
\end{table}


\subsubsection{Testing Procedure} \label{c3subsub:testing}

To compare the performance between the implemented algorithms, a randomized
stream of speed measurements (which represents the partition size in the BPP)
was generated, and each algorithms was compared with respect to the same streams
of data. 

\begin{table}[H] 
\centering 
\caption{Data to generate the measurement streams.} 
\label{table:testing_data} 
\begin{tabular}{ |c|l| } 
    \hline 
    \textbf{Symbol} & \textbf{Description} \\ 
    \hline 
    $P$ & Set of partitions of interest for the consumer group. \\ 
    $s_i(p)$ & Speed for a partition $p \in P$ at an iteration $i$ \\ 
    $\phi(\delta)$ & Uniform random function that selects a value between $[-\delta, \delta]$\\
    $C$ & Equivalent to \lstinline$ALGORITHM_CAPACITY$ \\
    \hline 
\end{tabular} 
\end{table}

To generate a stream of measurements, given $N$ (the number of measurements
desired) and $\delta$ (maximum relative speed variation between two sequential
iterations), at first the initial speed $s_0(p), \; \forall p \in P$ has to be
defined. Four different approaches were tested:
\begin{enumerate}
    \item Choosing a random value for the initial speed of each partition
        between $[0, 100]\% \cdot C$;
    \item Setting all partition's initial speed to $0\% \cdot C$;
    \item Setting all partition's initial speed to $50\% \cdot C$;
    \item Setting all partition's initial speed to $100\% \cdot C$.
\end{enumerate}

Given that there was no significant difference on the outcome when the initial
parition speed varied, for the remaining part of this section we will consider
the case where the initial speed was randomly selected between $[0, 100]\% \cdot
C$ for all partitions $p \in P$.

Therefore, given $s_0(p)\ \forall p \in P$, the remaining measurements were
obtained using: 
\begin{equation}
    s_i(p) = s_{i-1}(p) + \frac{\phi(\delta)}{100} \cdot C, \quad 
        \forall \ p \in P \ \wedge \ 
        i \in \{1, 2, ..., N-1\}
\end{equation}

Using the aformentioned procedure, 6 different streams of data were generated by
setting $N = 500$ and setting $\delta$ to a value belonging to the set
$\{0, 5, 10, 15, 20, 25\}$ for each stream of data ($\delta$ does not change
within a stream).

\subsubsection{Testing Metrics}

The metrics used to compare the performance between the algorithms are the
Cardinal Bin Score ($CBS_\delta(a)$) and the Average RScore ($E_\delta(R)$) over all iterations
of each stream.

\begin{table}[H] 
\centering 
\caption{Data to compute the cardinal bin score for a stream of measurements.} 
\label{table:bin_score} 
    \begin{tabular}{ |c|p{0.8\textwidth}| } 
    \hline 
    \textbf{Symbol} & \textbf{Description} \\ 
    \hline 
    $A$ & Set of algorithms implemented. \\ 
    $z_i^\delta(a)$ & number of bins used in iteration $i \in \{0, 1, ..., N-1\}$ for a
        stream defined by $\delta$ by an algorithm $a \in A$. \\ 
    \hline 
\end{tabular} 
\end{table}

The cardinal bin score is calculated using the following expression:
\begin{equation}
    CBS_\delta(a) = \frac{1}{N}
        \sum_{i=0}^{N-1} 
            \frac{  z_i^\delta(a) - min_{b \in A} \{z_i^\delta(b)\} }
                 {min_{b \in A} \{z_i^\delta(b)\} }, \ 
        \forall \ a \in A \ \wedge \ \delta \in \{0, 5, 10, 15, 20, 25\}. 
\end{equation}

The expected value of the Rscore, is used to compare the rebalance cost for a
single stream of data, and is computed as follows:
\begin{equation}
    E_\delta(R) = \frac{1}{N} 
        \sum_{i=0}^{N-1} R_i, \quad
        \forall \ \delta \in \{0, 5, 10, 15, 20, 25\}
\end{equation}

\subsubsection{Test Results}
\label{subsub:test_results}

\begin{figure}[htb!] 
\centering
\includegraphics[width=0.6\textwidth]{images/controller/relative.png} 
\caption{
    Cardinal Bin Score (CBS) for all implemented algorithms.
} 
\label{fig:relative_nconsumers} 
\end{figure}

In Figure \ref{fig:relative_nconsumers}, the worst performing algorithm is the
next fit followed by its decreasing version, which is due to every time a
partition has to be assigned, the algorithm only verifies if it fits in the last
created bin, as opposed to considering all existing bins. The remaining any fit
decreasing algorithms, are the ones that perform the best, with the best fit
decreasing consistently presenting the best results. 

\begin{figure}[htb!] 
\centering
\includegraphics[width=0.6\textwidth]{images/controller/filtered_relative.png} 
\caption{
    Cardinal Bin Score (CBS) filtered to present the modified and the
    BFD algorithms.
} 
\label{fig:relative_nconsumers_modified} 
\end{figure}

As for the modified versions of these algorithms, due to its sorting strategy,
MBFP shows the best results. It is also worth noting that for smaller
variabilities, the modified algorithms behave similarly to the online versions
of their any fit strategy with respect to the CBS, since the partitions aren't
necessarily assigned from biggest to smallest. On the other hand, the higher the
delta, the bigger the variability, which also leads to more rebalancing, having
the modified algorithms behave more like the decreasing versions of their fit
strategy.

\begin{figure}[htb!] 
    \centering
    \includegraphics[width=0.6\textwidth]{images/controller/Rscore.png}
    \caption{
        Impact on Rscore for different Deltas (random initial partition speed).
    } 
    \label{fig:rscore} 
\end{figure}

As can be seen in Figure \ref{fig:rscore}, the modified algorithms present the
best average Rscore for each stream of measurements along with the NFD. The
reason why the NFD presents such a result, is due to the increased amount of
consumers it creates to assign new partitions, which due to the procedure
exemplified in Figure \ref{fig:approximation_bin_creation}, will assign the
partition to the same consumer it is currently assigned to, as long as it has
not yet been created in the future assignment.

For a similar reason, the modified algorithms that perform the best with regards
to the Rscore, are also the ones that perform worst (compared to the remaining
modified algorithms) when evaluating the CBS.

To select the algorithm to use within the controller, there is a trade-off
between the aforementioned testing metrics. On account of the added rebalance
concern within the modified algorithms, these present an improvement with
regards to the rebalance cost when compared to the existing approximation
algorithms.

\begin{figure}[H] 
    \centering
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/controller/pareto_front/5.png}
        \caption{Pareto front for $\delta = 5$.}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/controller/pareto_front/10.png}
        \caption{Pareto front for $\delta = 10$.}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/controller/pareto_front/15.png}
        \caption{Pareto front for $\delta = 15$.}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/controller/pareto_front/20.png}
        \caption{Pareto front for $\delta = 20$.}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/controller/pareto_front/25.png}
        \caption{Pareto front for $\delta = 25$.}
    \end{subfigure}
    \caption{Pareto front for different deltas comparing the Cardinal Bin Score
    and the Average Rscore.}
    \label{fig:pareto_front} 
\end{figure}

The pareto front is a way of finding the set of solutions that are most
efficient, provided there are trade-offs within a multi-optimization problem.

Excluding MWFP, the modified algorithms are consistently a part of the pareto
front as shown in figure \ref{fig:pareto_front}, which implies these are a
competitive option as to which algorithm to pick for the reassign algorithm to
be executed in the controller. The algorithm that shows the best Rscore for the
different variabilities is the MWF, whereas the modified algorithm that performs
the best relative to the Cardinal Bin Score is the MBFP.

\subsection{State Group Management}
\label{sub:state_group_management}

This state is where the controller informs each consumer of their change in
state. Since there cannot be any concurrent read of a partition by two consumers
of the same consumer group, when rebalancing a partition, the controller has to:
inform the consumer currently assigned to the partition to stop
consuming from it; wait for confirmation that the consumer stopped consuming the
data; inform the new consumer of its new assignment.

This state not only handles this message exchange but it also creates and
deletes consumer and persistent volume resources from the Kubernetes cluster. 

\subsubsection{Difference between two Group States}

The current consumer group's state is represented by a list of consumers, each
having their own assignment (set of partitions). The new computed group's state
is defined as the next state, and is also a list of consumer's each having an
assignment, but representing the state the controller wants its consumer group
to achieve.

Similar to computing the difference between two sets, when computing the
difference between two consumer lists the procedure involves iterating over each
consumer (in both states), and calculating the difference between the two consumer
assignments (set of assigned partitions). There are three scenarios that result
in different actions the controller has to perform, for a given position $i$ of
each consumer list: 
\begin{itemize} 
    \item Next state has a consumer at $i$ but the current state does not - This
        means that the consumer has to be created by the controller, and the
        partitions assigned to the consumer in position $i$ of the next state,
        have to be associated with a StartConsumingCommand for this same
        consumer.  
    \item Next state does not have a consumer at $i$ but the current state
        does - The partitions associated with the consumer at position $i$ of
        the current state have to be associated with a StopConsumingCommand
        directed to this consumer, and the consumer has to be removed from the
        consumer group.  
    \item Both next state and current state have a consumer at position $i$ -
        This means that no creation or deletion operation has to be performed
        for this bin, and the operations to perform in this case are only
        communicating to the already existing consumer the difference in its
        assignment. 
    
        The same consumer has two different sets of partitions assigned to it
        represented in the two different group states.
        \lstinline[language=Python]{next_assignment} will denote the set of
        partitions attributed to the consumer's state in the next group's
        context, and \lstinline[language=Python]{current_assignment} is defined
        as the consumer's set of partitions in its current state.
    
\begin{lstlisting}[language=Python] 
partitions_stop = current_assignment - next_assignment 
partitions_start = next_assignment - current_assignment
\end{lstlisting} 
        The resulting set of partitions within \lstinline{partitions_stop} have
        to be included in a StopConsumingCommand, whereas the partitions in
        \lstinline{partitions_start} in a StartConsumingCommand, directed to
        consumer $i$.
\end{itemize}

\subsubsection{Managing the Consumer Group in the Kubernetes Cluster}

Each active consumer in the current group's state represents a deployment with
a single replica (pod), since each consumer requires a volume to persist its
data, which implies having a different volume for each pod. Assigning different
volumes to a set of pods is possible with stateful sets, but when removing an
instance from the set, only the highest index pod can be removed. In this
context, this does not provide with the necessary granularity as to which
consumer can be deleted. 

Consequently, each consumer is given an individual ID through its deployment's
\lstinline{metadata.name} property, a value that can be obtained within the pod
using the downwardAPI, that provides a pod with its context. This individual ID
assigned to the deployment's name, is the one used to inform the pod of its
metadata partition to consume from in the \lstinline{consumer.metadata} topic.

To allow the controller to create, list and delete the resources within the
cluster, a Kubernetes service account is used to authenticate the controller,
which is then given permissions for the aforementioned operations through a
Kubernetes Role. In this scenario, the controller's service account is linked
with a Role object that has permissions to create, list and delete deployment
and persistent volume claim resources.

Since all consumers have to be able to persist data, each consumer has to be
mapped to a persistent volume using a persistent volume claim. If it is the
first time a consumer with a given ID is being spawned, the controller has to
dynamically create and map a persistent volume claim to the consumer's
deployment.

To simplify the process, two template yaml files (Annexes \ref{appendix:template-pvc},
\ref{appendix:template-consumer}) are used, one for creating persistent volume
claims (PVC), and another used to create deployments. The controller is only
responsible for changing the template PVC ID when creating it. When the
controller has to create the deployment, it has to reference the created PVC in
the template deployment, and change the deployment's ID to the incremental ID
attributed by the controller.

As an example, if the controller has to create a consumer whose ID is $5$, it
would go through the following steps: 
\begin{enumerate} 
    \item If the PVC with name \lstinline{de-consumer-5-volume} does not yet
        exist, change the PVC metadata.name parameter to
        \lstinline{de-consumer-5-volume} in the template yaml file
        \ref{appendix:template-pvc}, and send the create request with the body
        containing the modified yaml file;
    \item Change the template deployment's \lstinline{metadata.name} parameter
        in the template yaml file \ref{appendix:template-consumer} to
        \lstinline{de-consumer-5}, and add a reference to the PVC created in the
        previous step.  
\end{enumerate}

\subsubsection{Communication between controller and Consumer Group}
\label{sub:controller_communication_cosumer}

Using the computed difference between the next and current group's state, each
consumer has a set of start and stop messages that have to be sent out by the
controller, for the group to reach the intended state. Each partition can have
associated to it at most two actions, which correspond to a start and/or a stop
command. 

Firstly, the controller prepares a batch of StartConsumingCommand messages, each
directed to a single consumer. For each partition in the set of unassigned
partitions, the partition ID is added to the StartConsumingCommand message that
is intended to the consumer that was assigned the partition.

Another batch of StopConsumingCommand messages is prepared, and for each
partition that has to be either rebalanced or removed, that partition's ID is
added to the message which is intended to the consumer that is currently
assigned to that partition. 

Each message the controller sends out to a consumer, has to be acknowledged by
the consumer with a corresponding event which can be one of two types,
StartConsumingEvent, StopConsumingEvent. Each of these messages contain a set of
partitions from which a consumer acted upon. For each partition contained within
one of the events, the controller removes its corresponding actions from the set
of actions that have to be deployed by the controller. 

If the received event is of type StopConsumingEvent, a new batch of
StartConsumingCommand records are prepared for the consumers that have to start
consuming from the partitions that are being rebalanced. This means that for
each partition referred in the StopConsumingEvent, if it has a corresponding
start action, the partition is added to the StartConsumingCommand directed to
the new consumer. 

When the controller sends a message to a consumer, it sends it to the same
partition as the consumer's ID in the \lstinline{consumer.metadata} topic. As for
the consumer, to communicate the event of having reacted to one of the
controller's commands, the record has to be sent to the partition with ID $0$ of
the same topic, as depicted in figure \ref{fig:system_architecture}.

This process terminates when there are no more actions to perform over any
partition, since the controller removes a start or stop action from a partition
as soon as it receives the acknowledgement by the consumer that it has performed
the corresponding command.

\subsection{State Synchronize}

This state exists to mitigate desynchronization between the consumer group's
state as perceived by the controller and the real state the group finds itself
in. The procedure involves having the controller query the Kubernetes cluster to
verify which are its active consumers, and with this information, it then
queries each consumer through their respective partitions in the
\lstinline{consumer.metadata} topic for their current state.  Only after all
active consumers have responded with their state does the controller proceed to
its normal behaviour triggering the transition to the Sentinel state. 
